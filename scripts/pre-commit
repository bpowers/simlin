#!/bin/bash
set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Determine repository root
REPO_ROOT="$(git rev-parse --show-toplevel)"

echo "The project passed all pre-commit checks before your changes. Any failing checks reported are the result of your changes and need to be fixed by addressing their root cause." >&2

echo "Running pre-commit checks..."

cd "$REPO_ROOT"


# 1. Check Rust formatting
echo -n "Checking Rust code formatting... "
if cargo fmt --check >/dev/null 2>&1; then
    echo -e "${GREEN}✓${NC}"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}Rust code needs formatting${NC}"
    echo -e "${YELLOW}Run 'cargo fmt' to fix formatting${NC}"
    exit 1
fi

# 2. Run Rust clippy
echo -n "Running Rust clippy... "
CLIPPY_OUTPUT="$(mktemp)"
if cargo clippy --all-targets --all-features -- -D warnings > "$CLIPPY_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$CLIPPY_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}Clippy found issues:${NC}"
    cat "$CLIPPY_OUTPUT"
    rm -f "$CLIPPY_OUTPUT"
    echo -e "${YELLOW}Run 'cargo clippy --all-targets --all-features -- -D warnings' to see errors${NC}"
    exit 1
fi

# 3. Run Rust tests
echo -n "Running Rust tests... "
TEST_OUTPUT="$(mktemp)"
if RUST_BACKTRACE=1 cargo test > "$TEST_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$TEST_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}Rust tests failed:${NC}"
    cat "$TEST_OUTPUT"
    rm -f "$TEST_OUTPUT"
    echo -e "${YELLOW}Run 'cargo test' to see failures${NC}"
    exit 1
fi

# Check if node_modules exists
if [ ! -d "node_modules" ]; then
    echo -e "${RED}node_modules is missing.${NC}"
    echo -e "${YELLOW}Run './scripts/cloud-init.sh' to install dependencies and configure the environment.${NC}"
    exit 1
fi

echo -n "Running TypeScript/JavaScript linting... "
LINT_OUTPUT="$(mktemp)"
if pnpm lint > "$LINT_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$LINT_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}Linting failed:${NC}"
    cat "$LINT_OUTPUT"
    rm -f "$LINT_OUTPUT"
    echo -e "${YELLOW}Run 'pnpm lint' to see errors${NC}"
    exit 1
fi

# Build WASM and TS packages before type-checking, so that
# .d.ts files from project references are up to date.
echo -n "Building WASM module... "
BUILD_OUTPUT="$(mktemp)"
if pnpm build > "$BUILD_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$BUILD_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}WASM build failed:${NC}"
    cat "$BUILD_OUTPUT"
    rm -f "$BUILD_OUTPUT"
    echo -e "${YELLOW}Run 'pnpm build' to see errors${NC}"
    exit 1
fi

echo -n "Checking TypeScript types... "
TSC_OUTPUT="$(mktemp)"
if pnpm tsc > "$TSC_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$TSC_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}TypeScript type checking failed:${NC}"
    cat "$TSC_OUTPUT"
    rm -f "$TSC_OUTPUT"
    echo -e "${YELLOW}Run 'pnpm tsc' to see errors${NC}"
    exit 1
fi

echo -n "Running TypeScript tests... "
TS_TEST_OUTPUT="$(mktemp)"
if pnpm test > "$TS_TEST_OUTPUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$TS_TEST_OUTPUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}TypeScript tests failed:${NC}"
    cat "$TS_TEST_OUTPUT"
    rm -f "$TS_TEST_OUTPUT"
    echo -e "${YELLOW}Run 'pnpm test' to see failures${NC}"
    exit 1
fi

# 5. Run pysimlin (Python) bindings tests on Python 3.11+
echo -n "Running pysimlin tests (Python 3.11+)... "
PY_OUT="$(mktemp)"
if scripts/pysimlin-tests.sh > "$PY_OUT" 2>&1; then
    echo -e "${GREEN}✓${NC}"
    rm -f "$PY_OUT"
else
    echo -e "${RED}✗${NC}"
    echo -e "${RED}pysimlin tests failed:${NC}"
    cat "$PY_OUT"
    rm -f "$PY_OUT"
    exit 1
fi

# 6. Make sure no cheating happened with tests
# This check uses either Claude CLI or Codex CLI depending on what's available

# The prompt for test quality checking
TEST_CHECK_PROMPT="the user is looking to commit code - at this point formatting and unit tests all pass.  Please review the diff of uncommitted work.  Tests and implementations shouldn't take shortcuts or be stubbed out/ignored (comments to the effect of 'real logic to test this would go here' are particularly damning, and the user is supposed to be doing TDD), but do a general high level review to ensure you understand the gestalt of the change. If there are important problems to address, start your response with 'FAIL: ' followed by a description of what is wrong, and what needs to happen. Provide guidance referencing CLAUDE.md, and tell the user to closely follow CLAUDE.md as they address the problem. If there are test shortcomings tell them they MUST NOT delete tests, the only way to succeed on the task is to fully implement the test. If the test and overall change look reasonable you MUST respond succinctly with the 1-word message: SUCCESS"

# Determine which AI tool to use
# Priority: 1) AI_TOOL env var, 2) .ai-tool-config file, 3) auto-detect
AI_CONFIG_FILE="$REPO_ROOT/.ai-tool-config"
if [ -n "$AI_TOOL" ]; then
    SELECTED_AI_TOOL="$AI_TOOL"
elif [ -f "$AI_CONFIG_FILE" ]; then
    SELECTED_AI_TOOL=$(cat "$AI_CONFIG_FILE")
else
    # Auto-detect: prefer claude, fall back to codex
    if command -v claude > /dev/null 2>&1; then
        SELECTED_AI_TOOL="claude"
    elif command -v codex > /dev/null 2>&1; then
        SELECTED_AI_TOOL="codex"
    else
        SELECTED_AI_TOOL="none"
    fi
fi

AI_OUTPUT="$(mktemp)"
AI_TIMEOUT=${AI_TIMEOUT:-300}

# Portable timeout wrapper (works on Linux and macOS)
# On macOS, 'timeout' is not available by default; use 'gtimeout' from coreutils or skip timeout
run_with_timeout() {
    local timeout_secs="$1"
    shift
    if command -v timeout > /dev/null 2>&1; then
        timeout -k 5 "$timeout_secs" "$@"
    elif command -v gtimeout > /dev/null 2>&1; then
        gtimeout -k 5 "$timeout_secs" "$@"
    else
        # No timeout command available, run without timeout
        "$@"
    fi
}

# Function to run the test check with Claude
run_claude_check() {
    local CLAUDE_BIN
    if command -v claude > /dev/null 2>&1; then
        CLAUDE_BIN=$(command -v claude)
    else
        CLAUDE_BIN="$HOME/.claude/local/claude"
    fi
    run_with_timeout "$AI_TIMEOUT" "$CLAUDE_BIN" -p --allowedTools 'Bash(git:*)' LS Read --model sonnet "$TEST_CHECK_PROMPT" > "$AI_OUTPUT" 2>&1
}

# Function to run the test check with Codex
run_codex_check() {
    run_with_timeout "$AI_TIMEOUT" codex exec -m gpt-5.3-codex-xhigh --full-auto "$TEST_CHECK_PROMPT" > "$AI_OUTPUT" 2>&1
}

echo -n "Running AI test quality check ($SELECTED_AI_TOOL)..."

case "$SELECTED_AI_TOOL" in
    claude)
        if run_claude_check; then
            if grep -q "^SUCCESS$" "$AI_OUTPUT"; then
                echo -e " ${GREEN}✓${NC}"
                rm -f "$AI_OUTPUT"
            else
                echo -e " ${RED}✗${NC}"
                echo -e "${RED}Test quality check failed:${NC}"
                cat "$AI_OUTPUT"
                rm -f "$AI_OUTPUT"
                exit 1
            fi
        else
            EXIT_CODE=$?
            # Exit code 124 = SIGTERM timeout, 137 = SIGKILL (128 + 9)
            if [ $EXIT_CODE -eq 124 ] || [ $EXIT_CODE -eq 137 ]; then
                echo -e " ${YELLOW}skipped (timeout)${NC}"
                echo -e "${YELLOW}Warning: Claude check timed out after ${AI_TIMEOUT}s. Skipping check.${NC}"
                rm -f "$AI_OUTPUT"
            else
                echo -e " ${RED}✗${NC}"
                echo -e "${RED}Claude check failed with exit code $EXIT_CODE${NC}"
                cat "$AI_OUTPUT"
                rm -f "$AI_OUTPUT"
                exit 1
            fi
        fi
        ;;
    codex)
        if run_codex_check; then
            if grep -q "SUCCESS" "$AI_OUTPUT"; then
                echo -e " ${GREEN}✓${NC}"
                rm -f "$AI_OUTPUT"
            else
                echo -e " ${RED}✗${NC}"
                echo -e "${RED}Test quality check failed:${NC}"
                cat "$AI_OUTPUT"
                rm -f "$AI_OUTPUT"
                exit 1
            fi
        else
            EXIT_CODE=$?
            if [ $EXIT_CODE -eq 124 ] || [ $EXIT_CODE -eq 137 ]; then
                echo -e " ${YELLOW}skipped (timeout)${NC}"
                echo -e "${YELLOW}Warning: Codex check timed out after ${AI_TIMEOUT}s. Skipping check.${NC}"
                rm -f "$AI_OUTPUT"
            else
                echo -e " ${RED}✗${NC}"
                echo -e "${RED}Codex check failed with exit code $EXIT_CODE${NC}"
                cat "$AI_OUTPUT"
                rm -f "$AI_OUTPUT"
                exit 1
            fi
        fi
        ;;
    none|*)
        echo -e " ${YELLOW}skipped (no AI tool available)${NC}"
        echo -e "${YELLOW}Warning: No AI tool configured. Run ./scripts/cloud-init.sh to set up.${NC}"
        rm -f "$AI_OUTPUT"
        ;;
esac

echo -e "${GREEN}All pre-commit checks passed!${NC}"
